import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False

def run():
    st.header("ğŸ”¬ æœºå™¨å­¦ä¹ å›å½’å»ºæ¨¡ï¼ˆæ•°å€¼å‹æ•°æ®ï¼‰")
    # 1. æ•°æ®ä¸Šä¼ 
    file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ CSV, Excelï¼‰", type=["csv", "xls", "xlsx"], key="reg_upload")
    if file is not None:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        elif file.name.endswith('.xls') or file.name.endswith('.xlsx'):
            df = pd.read_excel(file)
        else:
            st.error("ä»…æ”¯æŒCSVæˆ–Excelæ–‡ä»¶ï¼")
            st.stop()
        st.success(f"å·²è¯»å–æ–‡ä»¶ï¼š{file.name}")
        st.dataframe(df.head())
    else:
        st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
        st.stop()

    # 2. ç‰¹å¾/æ ‡ç­¾é€‰æ‹©
    with st.expander("1ï¸âƒ£ ç‰¹å¾ä¸æ ‡ç­¾é€‰æ‹©"):
        all_cols = df.columns.tolist()
        label_col = st.selectbox("é€‰æ‹©ç›®æ ‡ï¼ˆæ ‡ç­¾ï¼‰åˆ—", all_cols, key="reg_label")
        feature_cols = st.multiselect("é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆå¯å¤šé€‰ï¼‰", [c for c in all_cols if c != label_col], default=[c for c in all_cols if c != label_col], key="reg_feats")
        if not feature_cols or not label_col:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å’Œä¸€ä¸ªæ ‡ç­¾ï¼")
            st.stop()

    # 3. è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†
    with st.expander("2ï¸âƒ£ è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†"):
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
        random_state = st.number_input("éšæœºç§å­", 0, 9999, 42)
        X = df[feature_cols]
        y = df[label_col]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
        st.write(f"è®­ç»ƒé›†ï¼š{X_train.shape}ï¼Œæµ‹è¯•é›†ï¼š{X_test.shape}")

    # 4. æ¨¡å‹é€‰æ‹©
    with st.expander("3ï¸âƒ£ æ¨¡å‹é€‰æ‹©"):
        model_dict = {
            "çº¿æ€§å›å½’": LinearRegression,
            "å²­å›å½’": Ridge,
            "Lassoå›å½’": Lasso,
            "å¼¹æ€§ç½‘å›å½’": ElasticNet,
            "å†³ç­–æ ‘å›å½’": DecisionTreeRegressor,
            "éšæœºæ£®æ—å›å½’": RandomForestRegressor,
            "æ¢¯åº¦æå‡å›å½’": GradientBoostingRegressor,
            "XGBoostå›å½’": XGBRegressor,
            "LightGBMå›å½’": LGBMRegressor,
            "æ”¯æŒå‘é‡å›å½’": SVR,
        }
        model_names = list(model_dict.keys())
        selected_models = st.multiselect("é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹ï¼ˆå¯å¤šé€‰ï¼‰", model_names, default=["çº¿æ€§å›å½’", "éšæœºæ£®æ—å›å½’"])
        if not selected_models:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼")
            st.stop()

    # 4.1 æ¯ä¸ªæ¨¡å‹å‚æ•°è®¾ç½®
    model_params = {}
    for m in selected_models:
        with st.expander(f"{m} å‚æ•°è®¾ç½®"):
            params = {}
            if m == "çº¿æ€§å›å½’":
                fit_intercept = st.checkbox("fit_intercept", value=True, key=f"{m}_fit_intercept")
                params = {"fit_intercept": fit_intercept}
            elif m == "å²­å›å½’":
                alpha = st.number_input("alphaï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼‰", 0.0, 100.0, 1.0, key=f"{m}_alpha")
                fit_intercept = st.checkbox("fit_intercept", value=True, key=f"{m}_fit_intercept")
                max_iter = st.number_input("max_iterï¼ˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰", 10, 10000, 1000, key=f"{m}_max_iter")
                params = {"alpha": alpha, "fit_intercept": fit_intercept, "max_iter": max_iter}
            elif m == "Lassoå›å½’":
                alpha = st.number_input("alphaï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼‰", 0.0, 100.0, 1.0, key=f"{m}_alpha")
                fit_intercept = st.checkbox("fit_intercept", value=True, key=f"{m}_fit_intercept")
                max_iter = st.number_input("max_iterï¼ˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰", 10, 10000, 1000, key=f"{m}_max_iter")
                params = {"alpha": alpha, "fit_intercept": fit_intercept, "max_iter": max_iter}
            elif m == "å¼¹æ€§ç½‘å›å½’":
                alpha = st.number_input("alphaï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼‰", 0.0, 100.0, 1.0, key=f"{m}_alpha")
                l1_ratio = st.slider("l1_ratio", 0.0, 1.0, 0.5, key=f"{m}_l1_ratio")
                fit_intercept = st.checkbox("fit_intercept", value=True, key=f"{m}_fit_intercept")
                max_iter = st.number_input("max_iterï¼ˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰", 10, 10000, 1000, key=f"{m}_max_iter")
                params = {"alpha": alpha, "l1_ratio": l1_ratio, "fit_intercept": fit_intercept, "max_iter": max_iter}
            elif m == "å†³ç­–æ ‘å›å½’":
                max_depth = st.number_input("max_depthï¼ˆæœ€å¤§æ·±åº¦ï¼‰", 1, 50, 5, key=f"{m}_max_depth")
                params = {"max_depth": max_depth}
            elif m == "éšæœºæ£®æ—å›å½’":
                n_estimators = st.number_input("n_estimatorsï¼ˆæ ‘æ•°ï¼‰", 10, 1000, 100, key=f"{m}_n_estimators")
                max_depth = st.number_input("max_depthï¼ˆæœ€å¤§æ·±åº¦ï¼‰", 1, 50, 5, key=f"{m}_max_depth")
                params = {"n_estimators": n_estimators, "max_depth": max_depth}
            elif m == "æ¢¯åº¦æå‡å›å½’":
                n_estimators = st.number_input("n_estimatorsï¼ˆæ ‘æ•°ï¼‰", 10, 1000, 100, key=f"{m}_gbdt_n_estimators")
                learning_rate = st.number_input("learning_rateï¼ˆå­¦ä¹ ç‡ï¼‰", 0.001, 1.0, 0.1, key=f"{m}_learning_rate")
                params = {"n_estimators": n_estimators, "learning_rate": learning_rate}
            elif m == "XGBoostå›å½’":
                n_estimators = st.number_input("n_estimatorsï¼ˆæ ‘æ•°ï¼‰", 10, 1000, 100, key=f"{m}_xgb_n_estimators")
                learning_rate = st.number_input("learning_rateï¼ˆå­¦ä¹ ç‡ï¼‰", 0.001, 1.0, 0.1, key=f"{m}_xgb_learning_rate")
                params = {"n_estimators": n_estimators, "learning_rate": learning_rate}
            elif m == "LightGBMå›å½’":
                n_estimators = st.number_input("n_estimatorsï¼ˆæ ‘æ•°ï¼‰", 10, 1000, 100, key=f"{m}_lgb_n_estimators")
                learning_rate = st.number_input("learning_rateï¼ˆå­¦ä¹ ç‡ï¼‰", 0.001, 1.0, 0.1, key=f"{m}_lgb_learning_rate")
                params = {"n_estimators": n_estimators, "learning_rate": learning_rate}
            elif m == "æ”¯æŒå‘é‡å›å½’":
                C = st.number_input("Cï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼‰", 0.001, 100.0, 1.0, key=f"{m}_svr_C")
                kernel = st.selectbox("kernelï¼ˆæ ¸å‡½æ•°ï¼‰", ["rbf", "linear", "poly", "sigmoid"], key=f"{m}_svr_kernel")
                max_iter = st.number_input("max_iterï¼ˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰", 10, 10000, 1000, key=f"{m}_svr_max_iter")
                params = {"C": C, "kernel": kernel, "max_iter": max_iter}
            model_params[m] = params

    # 5. äº¤å‰éªŒè¯
    with st.expander("4ï¸âƒ£ äº¤å‰éªŒè¯"):
        use_cv = st.checkbox("å¯ç”¨äº¤å‰éªŒè¯", value=True)
        cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5) if use_cv else 1

    # 6. è®­ç»ƒä¸è¯„ä¼°
    if st.button("å¼€å§‹è®­ç»ƒå¹¶å¯¹æ¯”"):
        results = {}
        metrics_dict = {}
        figs_pred = []
        figs_res = []
        figs_imp = []
        for m in selected_models:
            model = model_dict[m](**model_params[m])
            model.fit(X_train, y_train)
            # äº¤å‰éªŒè¯
            if use_cv:
                cv = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)
                cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')
                st.write(f"[{m}] äº¤å‰éªŒè¯RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
            # æµ‹è¯•é›†è¯„ä¼°
            y_pred = model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            metrics_dict[m] = {"MSE": mse, "MAE": mae, "RÂ²": r2}
            # 1. é¢„æµ‹-çœŸå®å€¼æ•£ç‚¹å›¾ï¼ˆx=çœŸå®å€¼ï¼Œy=é¢„æµ‹å€¼ï¼ŒçœŸå®å€¼oè“è‰²ï¼Œé¢„æµ‹å€¼xæ©™è‰²ï¼Œå¸¦å›¾ä¾‹ï¼‰
            fig_pred, ax_pred = plt.subplots()
            idxs = np.arange(len(y_test))
            ax_pred.scatter(y_test, y_test, alpha=0.5, label='çœŸå®å€¼', marker='o', color='blue')
            ax_pred.scatter(y_test, y_pred, alpha=0.5, label='é¢„æµ‹å€¼', marker='x', color='orange')
            ax_pred.set_xlabel('çœŸå®å€¼')
            ax_pred.set_ylabel('é¢„æµ‹å€¼')
            ax_pred.set_title(f'{m} æµ‹è¯•é›†é¢„æµ‹-çœŸå®å€¼')
            ax_pred.legend()
            figs_pred.append(fig_pred)
            # 2. æ®‹å·®åˆ†å¸ƒå›¾
            fig_res, ax_res = plt.subplots()
            residuals = y_test - y_pred
            sns.histplot(residuals, bins=30, kde=True, ax=ax_res)
            ax_res.set_title(f'{m} æ®‹å·®åˆ†å¸ƒ')
            ax_res.set_xlabel('æ®‹å·®')
            figs_res.append(fig_res)
            # 3. ç‰¹å¾é‡è¦æ€§æˆ–ç³»æ•°
            fig_imp = None
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)
                fig_imp, ax_imp = plt.subplots()
                feat_imp.plot(kind='bar', ax=ax_imp)
                ax_imp.set_title(f'{m} ç‰¹å¾é‡è¦æ€§')
                ax_imp.set_ylabel('é‡è¦æ€§')
                ax_imp.set_xlabel('ç‰¹å¾')
            elif hasattr(model, 'coef_'):
                coef = model.coef_
                if coef.ndim == 1:
                    feat_imp = pd.Series(coef, index=feature_cols).sort_values(ascending=False)
                else:
                    feat_imp = pd.Series(coef[0], index=feature_cols).sort_values(ascending=False)
                fig_imp, ax_imp = plt.subplots()
                feat_imp.plot(kind='bar', ax=ax_imp)
                ax_imp.set_title(f'{m} ç³»æ•°')
                ax_imp.set_ylabel('ç³»æ•°')
                ax_imp.set_xlabel('ç‰¹å¾')
            figs_imp.append(fig_imp)
            results[m] = model
        # ä¸»è¦æŒ‡æ ‡è¡¨æ ¼
        # st.subheader("å„æ¨¡å‹ä¸»è¦æŒ‡æ ‡å¯¹æ¯”")
        # metrics_df = pd.DataFrame(metrics_dict)
        # st.dataframe(metrics_df.style.format("{:.4f}"), use_container_width=True)
        # å…ˆæ¯ä¸ªæ¨¡å‹å•ç‹¬å±•ç¤ºæ‰€æœ‰æŒ‡æ ‡å’Œå›¾
        st.subheader("æ¯ä¸ªæ¨¡å‹è¯¦ç»†ä¿¡æ¯ä»¥åŠå¯è§†åŒ–å±•ç¤º")
        for i, m in enumerate(selected_models):
            st.markdown(f"#### {m}")
            # å•ç‹¬æ˜¾ç¤ºæŒ‡æ ‡
            r2 = metrics_dict[m]["RÂ²"]
            mae = metrics_dict[m]["MAE"]
            mse = metrics_dict[m]["MSE"]
            st.write(f"RÂ²: {r2:.4f}  |  MAE: {mae:.4f}  |  MSE: {mse:.4f}")
            row = st.columns(3)
            with row[0]:
                st.pyplot(figs_pred[i])
            with row[1]:
                st.pyplot(figs_res[i])
            with row[2]:
                if figs_imp[i] is not None:
                    st.pyplot(figs_imp[i])
                else:
                    st.info("è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§æˆ–ç³»æ•°å±•ç¤º")

        # æœ€åç»Ÿä¸€æ±‡æ€»å¯¹æ¯”è¡¨æ ¼ï¼Œè¡Œä¸ºæ¨¡å‹ï¼Œåˆ—ä¸ºRÂ²ã€MAEã€MSE
        st.subheader("å„æ¨¡å‹æŒ‡æ ‡å¯¹æ¯”æ±‡æ€»")
        metrics_df = pd.DataFrame(metrics_dict).T
        metrics_df = metrics_df[["RÂ²", "MAE", "MSE"]]
        st.dataframe(metrics_df.style.format("{:.4f}"), use_container_width=True)
        # æœ€åå¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„æµ‹è¯•é›†æ‹Ÿåˆæ›²çº¿
        st.subheader("å„æ¨¡å‹æµ‹è¯•é›†æ‹Ÿåˆæ›²çº¿å¯¹æ¯”")
        n_models = len(selected_models)
        for i in range(0, n_models, 3):
            cols = st.columns(3)
            for j, idx in enumerate(range(i, min(i+3, n_models))):
                m = selected_models[idx]
                with cols[j]:
                    st.markdown(f"**{m}**")
                    st.pyplot(figs_pred[idx])
        
       
